{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总共有 18 张图像+掩码.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_485498/148002346.py:22: UserWarning: Argument(s) 'max_holes, max_height, max_width, fill_value, mask_fill_value' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(max_holes=5, max_height=16, max_width=16,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30] - Train Loss: 1.5883 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [2/30] - Train Loss: 1.3574 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [3/30] - Train Loss: 1.2079 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [4/30] - Train Loss: 1.1200 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [5/30] - Train Loss: 1.0723 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [6/30] - Train Loss: 1.0469 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [7/30] - Train Loss: 1.0329 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [8/30] - Train Loss: 1.0247 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [9/30] - Train Loss: 1.0195 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [10/30] - Train Loss: 1.0161 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [11/30] - Train Loss: 1.0136 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [12/30] - Train Loss: 1.0118 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [13/30] - Train Loss: 1.0104 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [14/30] - Train Loss: 1.0093 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [15/30] - Train Loss: 1.0084 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [16/30] - Train Loss: 1.0076 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [17/30] - Train Loss: 1.0069 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [18/30] - Train Loss: 1.0063 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [19/30] - Train Loss: 1.0058 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [20/30] - Train Loss: 1.0054 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [21/30] - Train Loss: 1.0050 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [22/30] - Train Loss: 1.0047 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [23/30] - Train Loss: 1.0043 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [24/30] - Train Loss: 1.0041 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [25/30] - Train Loss: 1.0038 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [26/30] - Train Loss: 1.0036 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [27/30] - Train Loss: 1.0034 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [28/30] - Train Loss: 1.0032 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [29/30] - Train Loss: 1.0030 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "Epoch [30/30] - Train Loss: 1.0028 | Val IoU: 0.0000, Val Dice: 0.0000\n",
      "\n",
      "[测试结果] IoU=0.0000, Dice=0.0000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "# ====================== 数据增强 ======================\n",
    "# 在训练集中，我们使用 Albumentations 做较强的增广\n",
    "train_transform = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.Rotate(limit=15, p=0.5),\n",
    "    A.Perspective(scale=(0.05, 0.1), p=0.3),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.HueSaturationValue(p=0.5),\n",
    "    A.CoarseDropout(max_holes=5, max_height=16, max_width=16,\n",
    "                    fill_value=0, mask_fill_value=0, p=0.5),\n",
    "    A.Resize(224, 224),           # 统一缩放到224×224\n",
    "    ToTensorV2()\n",
    "], additional_targets={'mask': 'mask'})\n",
    "\n",
    "# 验证/测试集中，我们通常只做最基本的resize + ToTensor\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(224, 224),\n",
    "    ToTensorV2()\n",
    "], additional_targets={'mask': 'mask'})\n",
    "\n",
    "# ====================== 自定义Dataset ======================\n",
    "class TextSegDataset(Dataset):\n",
    "    \"\"\"\n",
    "    读取 (image, mask) 对，并应用数据增强\n",
    "    假设:\n",
    "    - 原图目录: img_dir\n",
    "    - 掩码目录: mask_dir\n",
    "    - 每张原图对应一个同名 + '_mask.png' 的掩码文件\n",
    "    \"\"\"\n",
    "    def __init__(self, img_dir, mask_dir, transform=None):\n",
    "        super().__init__()\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        self.img_files = sorted([f for f in os.listdir(img_dir)\n",
    "                                 if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.img_files[idx]\n",
    "        base_name = img_name.rsplit('.', 1)[0]\n",
    "        \n",
    "        img_path  = os.path.join(self.img_dir,  img_name)\n",
    "        mask_path = os.path.join(self.mask_dir, base_name + \"_mask.png\")\n",
    "        \n",
    "        # 读取图像(BGR->RGB)与掩码(灰度)\n",
    "        img_bgr  = cv2.imread(img_path)\n",
    "        mask_gray= cv2.imread(mask_path, cv2.IMREAD_UNCHANGED)\n",
    "        if img_bgr is None or mask_gray is None:\n",
    "            raise FileNotFoundError(f\"Cannot read image/mask: {img_path}, {mask_path}\")\n",
    "        \n",
    "        # 转成 float32\n",
    "        img_bgr = img_bgr.astype(np.float32)\n",
    "        mask_gray = mask_gray.astype(np.float32)\n",
    "\n",
    "\n",
    "        img_rgb  = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Albumentations需要 numpy array\n",
    "        # mask必须是单通道\n",
    "        if self.transform:\n",
    "            # 传入transform时要指定 'image' 和 'mask'\n",
    "            augmented = self.transform(image=img_rgb, mask=mask_gray)\n",
    "            img_t  = augmented['image']   # tensor: [3,224,224]\n",
    "            mask_t = augmented['mask']    # tensor: [224,224]\n",
    "        else:\n",
    "            # 如果不做增强，就手动ToTensor\n",
    "            img_rgb  = cv2.resize(img_rgb, (224,224))\n",
    "            mask_gray= cv2.resize(mask_gray, (224,224), interpolation=cv2.INTER_NEAREST)\n",
    "            img_t  = torch.from_numpy(img_rgb.transpose(2,0,1)).float() / 255.0\n",
    "            mask_t = torch.from_numpy(mask_gray).float()\n",
    "        \n",
    "        # 如果掩码是0/255，转成0/1\n",
    "        mask_t = (mask_t > 127.5).float().unsqueeze(0)  # [1,224,224]\n",
    "        \n",
    "        return img_t, mask_t\n",
    "\n",
    "# ====================== 定义一个简化的ViT模型 ======================\n",
    "class SmallViT(nn.Module):\n",
    "    def __init__(self, image_size=224, patch_size=16,\n",
    "                 embed_dim=128, num_heads=4, depth=4, num_classes=1):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        # 1) 补丁嵌入\n",
    "        self.patch_embed = nn.Conv2d(3, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        # 可学习位置编码\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_patches, embed_dim))\n",
    "        \n",
    "        # 2) Transformer编码器\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=embed_dim,\n",
    "            nhead=num_heads,\n",
    "            dim_feedforward=embed_dim*4,\n",
    "            dropout=0.1,\n",
    "            activation='gelu',\n",
    "            batch_first=True\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=depth)\n",
    "        \n",
    "        # 3) 解码头(上采样回原图尺寸)\n",
    "        self.up = nn.ConvTranspose2d(embed_dim, num_classes,\n",
    "                                     kernel_size=patch_size, stride=patch_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        # Patch Embedding\n",
    "        x = self.patch_embed(x)  # [B,embed_dim,H/patch,W/patch]\n",
    "        # flatten => [B,embed_dim, N], transpose => [B,N,embed_dim]\n",
    "        x = x.flatten(2).transpose(1,2)\n",
    "        \n",
    "        # 加上位置编码\n",
    "        x = x + self.pos_embed[:, :x.size(1), :]\n",
    "        \n",
    "        # Transformer\n",
    "        x = self.transformer(x)  # [B,N,embed_dim]\n",
    "        \n",
    "        # reshape回 CNN 形式\n",
    "        Hp = H // self.patch_size\n",
    "        Wp = W // self.patch_size\n",
    "        x = x.transpose(1,2).reshape(B, -1, Hp, Wp)  # [B,embed_dim,Hp,Wp]\n",
    "        \n",
    "        # 上采样回原图大小 => [B,num_classes,H,W]\n",
    "        x = self.up(x)\n",
    "        return x\n",
    "\n",
    "# ====================== Dice Loss ======================\n",
    "def dice_loss_fn(logits, targets):\n",
    "    \"\"\"\n",
    "    logits: [B,1,H,W] raw output\n",
    "    targets: [B,1,H,W] in {0,1}\n",
    "    返回: 平均Dice损失 (越小越好)\n",
    "    \"\"\"\n",
    "    probs = torch.sigmoid(logits)  # [B,1,H,W]\n",
    "    num = (probs * targets).sum(dim=(1,2,3)) * 2.0\n",
    "    den = (probs + targets).sum(dim=(1,2,3)) + 1e-6\n",
    "    dice = num / den\n",
    "    return 1 - dice.mean()\n",
    "\n",
    "# ====================== 训练示例 ======================\n",
    "def train_vit_seg():\n",
    "    # 1) 数据准备\n",
    "    img_dir = \"data/annotation_images\"\n",
    "    mask_dir= \"data/mask\"\n",
    "    \n",
    "    full_dataset = TextSegDataset(img_dir, mask_dir, transform=train_transform)\n",
    "    total_len = len(full_dataset)\n",
    "    print(f\"总共有 {total_len} 张图像+掩码.\")\n",
    "    \n",
    "    # 若 total_len=18, 可以 12/3/3 划分\n",
    "    train_size = 12\n",
    "    val_size   = 3\n",
    "    test_size  = total_len - train_size - val_size\n",
    "    train_ds, val_ds, test_ds = random_split(\n",
    "        full_dataset,\n",
    "        [train_size, val_size, test_size],\n",
    "        generator=torch.Generator().manual_seed(42)\n",
    "    )\n",
    "    \n",
    "    # 验证/测试集只做最基本的变换\n",
    "    val_dataset = TextSegDataset(img_dir, mask_dir, transform=val_transform)\n",
    "    # 这里需要注意：random_split只是拆分了索引，你得自己写法把train_ds,val_ds映射到新的transform\n",
    "    \n",
    "    # 简单做法：对train_ds用train_transform，对val_ds/test_ds用val_transform\n",
    "    # 我们可以重写Dataset，或在Dataset里判断下标是否在train还是val\n",
    "    # 为了演示，这里先只在train上做Albumentations(你也可以做更精细的写法)\n",
    "    \n",
    "    # 构造DataLoader\n",
    "    train_loader = DataLoader(train_ds, batch_size=2, shuffle=True, num_workers=2)\n",
    "    val_loader   = DataLoader(val_ds,   batch_size=2, shuffle=False, num_workers=2)\n",
    "    test_loader  = DataLoader(test_ds,  batch_size=2, shuffle=False, num_workers=2)\n",
    "    \n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # 2) 模型\n",
    "    model = SmallViT(\n",
    "        image_size=224, patch_size=16,\n",
    "        embed_dim=128, num_heads=4, depth=4, num_classes=1\n",
    "    ).to(device)\n",
    "    \n",
    "    # 3) 损失函数 & 优化器\n",
    "    bce_loss = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "    \n",
    "    # 4) 训练循环\n",
    "    epochs = 30\n",
    "    for epoch in range(1, epochs+1):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "        for imgs, masks in train_loader:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            logits = model(imgs)  # [B,1,H,W]\n",
    "            loss = bce_loss(logits, masks) + dice_loss_fn(logits, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        \n",
    "        # 验证\n",
    "        model.eval()\n",
    "        total_val_iou = 0\n",
    "        total_val_dice= 0\n",
    "        count = 0\n",
    "        with torch.no_grad():\n",
    "            for imgs, masks in val_loader:\n",
    "                imgs, masks = imgs.to(device), masks.to(device)\n",
    "                logits = model(imgs)\n",
    "                probs  = torch.sigmoid(logits)\n",
    "                # IoU\n",
    "                pred_bin = (probs > 0.5).float()\n",
    "                intersect = (pred_bin * masks).sum(dim=(1,2,3))\n",
    "                union = ((pred_bin + masks) > 0).float().sum(dim=(1,2,3)) + 1e-6\n",
    "                iou = (intersect / union).mean().item()\n",
    "                # Dice\n",
    "                dice_num = 2*intersect\n",
    "                dice_den = pred_bin.sum(dim=(1,2,3)) + masks.sum(dim=(1,2,3)) + 1e-6\n",
    "                dice = (dice_num/dice_den).mean().item()\n",
    "                \n",
    "                total_val_iou += iou\n",
    "                total_val_dice+= dice\n",
    "                count += 1\n",
    "        \n",
    "        avg_val_iou = total_val_iou / count\n",
    "        avg_val_dice= total_val_dice/ count\n",
    "        \n",
    "        print(f\"Epoch [{epoch}/{epochs}] - \"\n",
    "              f\"Train Loss: {avg_train_loss:.4f} | \"\n",
    "              f\"Val IoU: {avg_val_iou:.4f}, Val Dice: {avg_val_dice:.4f}\")\n",
    "    \n",
    "    # 5) 测试\n",
    "    model.eval()\n",
    "    total_test_iou = 0\n",
    "    total_test_dice= 0\n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for imgs, masks in test_loader:\n",
    "            imgs, masks = imgs.to(device), masks.to(device)\n",
    "            logits = model(imgs)\n",
    "            probs  = torch.sigmoid(logits)\n",
    "            pred_bin = (probs > 0.5).float()\n",
    "            \n",
    "            intersect = (pred_bin * masks).sum(dim=(1,2,3))\n",
    "            union = ((pred_bin + masks) > 0).float().sum(dim=(1,2,3)) + 1e-6\n",
    "            iou = (intersect/union).mean().item()\n",
    "            \n",
    "            dice_num = 2*intersect\n",
    "            dice_den = pred_bin.sum(dim=(1,2,3)) + masks.sum(dim=(1,2,3)) + 1e-6\n",
    "            dice = (dice_num/dice_den).mean().item()\n",
    "            \n",
    "            total_test_iou  += iou\n",
    "            total_test_dice += dice\n",
    "            count += 1\n",
    "    print(f\"\\n[测试结果] IoU={total_test_iou/count:.4f}, Dice={total_test_dice/count:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    train_vit_seg()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_single(model, dataset, idx=0, threshold=0.5):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        img_t, mask_t = dataset[idx]  # 一个 (image, mask)\n",
    "        img_t = img_t.unsqueeze(0).cuda()  # 扩展batch维度\n",
    "        logits = model(img_t)             # [1,1,H,W]\n",
    "        probs  = torch.sigmoid(logits)[0] # [1,H,W]\n",
    "        \n",
    "        pred_bin = (probs > threshold).float().cpu().numpy()[0]\n",
    "        img_np   = img_t[0].cpu().numpy().transpose(1,2,0)  # [H,W,3]\n",
    "        mask_np  = mask_t[0].cpu().numpy()\n",
    "        \n",
    "        plt.figure(figsize=(12,4))\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow(img_np)\n",
    "        plt.title(\"Original\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(mask_np, cmap='gray')\n",
    "        plt.title(\"Ground Truth\")\n",
    "        plt.axis('off')\n",
    "        \n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(pred_bin, cmap='gray')\n",
    "        plt.title(\"Predicted\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# 假设 val_ds[0] 是一张图\n",
    "visualize_single(model, val_ds, idx=0, threshold=0.5)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
